#
# Copyright The NOMAD Authors.
#
# This file is part of NOMAD. See https://nomad-lab.eu for further info.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import plotly.express as px
import plotly.graph_objects as go

import numpy as np
from PIL import Image
import base64
import io
import pint
import struct # for binary files

from nomad.datamodel.metainfo.plot import PlotSection
from nomad.datamodel.metainfo.eln import ELNMeasurement
#from nomad.parsing.tabular import TableData
from nomad.datamodel.data import UserReference, AuthorReference
from nomad.datamodel.metainfo.eln import ELNSubstance
from nomad.datamodel.metainfo.basesections.v1 import ReadableIdentifiers
from nomad.datamodel.metainfo.basesections.v1 import PureSubstance
from nomad.datamodel.metainfo.basesections.v1 import PureSubstanceSection
from nomad.datamodel.metainfo.eln import ELNInstrument
from nomad.datamodel.metainfo.eln import Chemical
from nomad.datamodel.data import EntryData




from typing import (
    TYPE_CHECKING,
)
from nomad.metainfo import (
    MSection,
    Package,
    Quantity,
    SubSection,
    MEnum,
    Reference,
    Datetime,
    Section,
)
from nomad.datamodel.data import (
    EntryData,
    ArchiveSection,
)
from nomad.datamodel.data import (
    EntryDataCategory,
)
from nomad.metainfo.metainfo import (
    Category,
)
from nomad.units import ureg
from nomad.datamodel.metainfo.plot import (
    PlotlyFigure,
    PlotSection,
)

if TYPE_CHECKING:
    from nomad.datamodel.datamodel import (
        EntryArchive,
    )
    from structlog.stdlib import (
        BoundLogger,
    )

m_package = Package(name='CRC1415 Sample ELN Molecule')


class DataFileError(Exception):
    """Custom exception for data file errors."""
    pass


class CRC1415Category(EntryDataCategory):
    """
    A category for all plugins defined in the `crc1415-plugin` plugin.
    """

    m_def = Category(label='CRC1415', categories=[EntryDataCategory])

class CRC1415Chemical(Chemical, EntryData, ArchiveSection):
    '''
    This is an example description for Chemical.
    A description can contain **markdown** markup and TeX formulas, like $\\sum\\limits_{i=0}^{n}$.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-Chemical',
    )
    form = Quantity(
        type=MEnum(['crystalline solid', 'powder', 'solution']),
        a_eln={
            "component": "EnumEditQuantity"
        },
    )
    cas_number = Quantity(
        type=str,
        a_eln={
            "component": "StringEditQuantity"
        },
    )
    ec_number = Quantity(
        type=str,
        a_eln={
            "component": "StringEditQuantity"
        },
    )

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        '''
        The normalizer for the `CRC1415Chemical` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        '''
        super().normalize(archive, logger)


class Instrument(ELNInstrument, EntryData, ArchiveSection):
    '''
    Class autogenerated from yaml schema.
    '''
    m_def = Section()

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        '''
        The normalizer for the `Instrument` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        '''
        super().normalize(archive, logger)


class IRInstrument(Instrument, ArchiveSection):
    '''
    Class autogenerated from yaml schema.
    '''
    m_def = Section()


class Contributors(ArchiveSection):
    '''
    Class autogenerated from yaml schema.
    '''
    m_def = Section()
    Contributors = Quantity(
        type=AuthorReference,
        a_eln={
            "component": "AuthorEditQuantity"
        },
    )


#class XRDMeasurement(ELNMeasurement, TableData, PlotSection, ArchiveSection):
class MeasurementXRD(ELNMeasurement, PlotSection, ArchiveSection):
    '''
    Class for handling measurement of XRD.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-Measurement-XRD',
        a_eln={
            "overview": True,
            "hide": [
                "name",
                "lab_id",
                "method",
                "samples",
                "measurement_identifiers"
            ]
        },
        # a_plotly_graph_object=[
        #     {
        #         "data": [
        #             {
        #                 "x": "#Deg2Theta",
        #                 "y": "#Counts"
        #             }
        #         ],
        #         "layout": {
        #             "title": {
        #                 "text": "Counts over Degree 2Theta"
        #             }
        #         }
        #     }
        # ],
        )
    lab_id = Quantity(
        type=str,
        a_display={
            "visible": False
        },
    )
    
    datetime_end = Quantity(
        type=Datetime,
        description='The date and time when this activity has ended.',
        a_eln=dict(component='DateTimeEditQuantity', label='ending Time'),
    )
    
    data_as_raw_or_xyd_file = Quantity(
        type=str,
        description='''
        A reference to an uploaded .raw or .xyd produced by the XRD instrument.
        ''',
        a_browser={
            "adaptor": "RawFileAdaptor"
        },
        a_eln={
            "component": "FileEditQuantity"
        },
    )
    Deg2Theta = Quantity(
        type=np.float64,
        a_tabular={
            "name": "Deg2Theta"
        },
        shape=["*"],
        unit='deg',
        description='The 2-theta range of the diffractogram',
    )
    Intensity = Quantity(
        type=np.float64,
        a_tabular={
            "name": "Counts"
        },
        shape=["*"],
        unit='dimensionless',
        description='The count at each 2-theta value, dimensionless',
    )
    
    def generate_plots(self) -> list[PlotlyFigure]:
        """
        Generate the plotly figures for the `MeasurementXRD` section.

        Returns:
            list[PlotlyFigure]: The plotly figures.
        """
        figures = []
        #if self.wavelength is None:
        #    return figures

        x_label = '2Theta'
        xaxis_title = f'{x_label} (Â°)'
        x = self.Deg2Theta.to('degree').magnitude

        y_label = 'Intensity'
        yaxis_title = f'{y_label} (a.u.)'
        y = self.Intensity.to('dimensionless').magnitude

        line_linear = px.line(x=x, y=y)

        line_linear.update_layout(
            title=f'{y_label} over {x_label}',
            xaxis_title=xaxis_title,
            yaxis_title=yaxis_title,
            xaxis=dict(
                fixedrange=False,
            ),
            yaxis=dict(
                fixedrange=False,
            ),
            template='plotly_white',
        )

        figures.append(
            PlotlyFigure(
                label=f'{y_label} linear plot',
                index=0,
                figure=line_linear.to_plotly_json(),
            ),
        )

        return figures
    
    def unpack_repeated_bytes(self, byte_data, data_type, count):
        """
        Unpack a series of bytes into a tuple of the same data type.

        :param byte_data: The bytes to unpack.
        :param data_type: The format character for the data type (e.g., 'b' for signed char).
        :param count: The number of items to unpack.
        :return: A tuple of unpacked values.
        """
        # Create the format string based on the data type and count
        format_string = f'{count}{data_type}'
        
        # Unpack the byte data using the constructed format string
        return struct.unpack(format_string, byte_data)  
    
    def get_non_empty_chunks_separated_by_null(self, data_slice):
        """
        Get all non-empty chunks of data separated by NULL bytes.

        :param data_slice: The slice of data to split.
        :return: A list of bytes objects, each representing a non-empty chunk of data.
        """
        # Split the data by NULL bytes and filter out empty chunks
        return [chunk for chunk in data_slice.split(b'\x00') if chunk]
    
    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger'):
        """
        The normalize function of the `MeasurementXRD` section.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        # super().normalize(archive, logger)
        
        try:
            # Check if any file is provided
            if self.data_as_raw_or_xyd_file:
                # Check if the file has the correct extension
                if not self.data_as_raw_or_xyd_file.endswith('.xyd') and not self.data_as_raw_or_xyd_file.endswith('.raw'):
                    raise DataFileError(f"The file '{self.data_as_raw_or_xyd_file}' must have a .raw or .xyd extension.")
                    
                if self.data_as_raw_or_xyd_file.endswith('.xyd'):
                    # Otherwise parse the file
                    with archive.m_context.raw_file(self.data_as_raw_or_xyd_file) as xydfile:
                        # Load the data from the file
                        dataxydfile = np.loadtxt(xydfile)
                        
                        # Separate the columns into two variables and copy to 
                        self.Deg2Theta = ureg.Quantity(dataxydfile[:, 0], 'degree') # dataxydfile[:, 0]  # First column
                        self.Intensity = ureg.Quantity(dataxydfile[:, 1], 'dimensionless') #dataxydfile[:, 1]  # Second column
                        
                        # Otherwise create plot
                        self.figures = self.generate_plots()
                        
                if self.data_as_raw_or_xyd_file.endswith('.raw'):
                    # Otherwise parse the file
                    with archive.m_context.raw_file(self.data_as_raw_or_xyd_file,'rb') as rawfile:
                        # Load the data from the file
                        contentrawfile = rawfile.read()
                        
                        ###
                        # File Type Version
                        ###
                        count = len(contentrawfile[0x00:0x0D + 1])//1 # Number of bytes to unpack
                        #print(count)
                        unpacked_data = self.unpack_repeated_bytes(contentrawfile[0x00:0x0D + 1], 'b', count)
                            
                        # Convert unpacked data to a string
                        string_output_file_type = ''.join(chr(b) for b in unpacked_data)
                        
                        if string_output_file_type != 'RAW_1.06Powdat':
                            logger.warn(f'This reader may not work for raw file with header: "{string_output_file_type}"')
                        
                        ###
                        # Date of Experiment
                        ###

                        datasplice = contentrawfile[0x0010:0x001F + 1]
                        count = len(datasplice)//1 # Number of bytes to unpack
                        #print(count)
                        unpacked_data = self.unpack_repeated_bytes(datasplice, 'b', count)
                            
                        # Convert unpacked data to a string
                        string_output_day = ''.join(chr(b) for b in unpacked_data)
                        
                        # Convert the unpacked data as a datetime object
                        from dateutil import parser as dataparser
                        dt = dataparser.parse(string_output_day)
                        self.datetime = dt 
                        
                        ###
                        # File Name And Comments?
                        ###
                        datasplice = contentrawfile[0x0020:0x012F + 1]
                        
                        # Get all chunks separated by NULL bytes in the data slice
                        chunks = self.get_non_empty_chunks_separated_by_null(datasplice)
                        
                        # Only add description if nothing is there
                        if not self.description:
                            self.description = ''
                            
                            # Print the result chunks
                            for i, chunk in enumerate(chunks):
                                #print(f'Chunk {i}: {chunk}')
                                count = len(chunk)//1 # Number of bytes to unpack (1 for char)
                                unpacked_data = self.unpack_repeated_bytes(chunk, 'b', count)
                                string_output_description = ''.join(chr(b) for b in unpacked_data)
                                # Print the unpacked data as a string
                                self.description += '<p>'+string_output_description + '</p>\n'
                                #print(string_output)
                                
                        ###
                        # Start and End Time
                        ###
                        datasplice = contentrawfile[4*0x10000+0x0600:4*0x10000+0x0620]
                        #print(datasplice)
                        # Get all chunks separated by NULL bytes in the data slice
                        chunks = self.get_non_empty_chunks_separated_by_null(datasplice)
                            
                        # Print the result chunks
                        # for i, chunk in enumerate(chunks):
                        #     print(f'Chunk {i}: {chunk}')
                        #     count = len(chunk)//1 # Number of bytes to unpack (1 for char)
                        #     unpacked_data = self.unpack_repeated_bytes(chunk, 'b', count)
                        #     string_output_time = ''.join(chr(b) for b in unpacked_data)
                        #     # Print the unpacked data as a string
                        #     print(string_output_time)
                        #
                        # print(len(chunks), chunks[1])
                        
                        
                        if len(chunks) > 1:
                            count = len(chunks[1])//1 # Number of bytes to unpack (1 for char)
                            unpacked_data = self.unpack_repeated_bytes(chunks[1], 'b', count)
                            string_output_time = ''.join(chr(b) for b in unpacked_data)
                            
                            from dateutil import parser as dataparser
                            dt = dataparser.parse(string_output_time)
                            self.datetime_end = dt 
                        
                        ###
                        # Number of Data Entries
                        ###
                        datasplice = contentrawfile[4*0x10000+0x0622:4*0x10000+0x0624]
                        # 'i': Integer (4 bytes)
                        # 'f': Float (4 bytes)
                        # 'd': Double (8 bytes)
                        # 'h': Short (2 bytes)
                        count = len(datasplice)//2 # Number of bytes to unpack (1 for char)
                        #print(count)
                        unpacked_data = self.unpack_repeated_bytes(datasplice, 'h', count)
                        countDataEntries=int(unpacked_data[0])
                        # print(countDataEntries)
                        
                        ###
                        # x-range
                        ###
                        datasplice = contentrawfile[4*0x10000+0x062C:4*0x10000+0x0638]
                        
                        #'i': Integer (4 bytes)
                        #'f': Float (4 bytes)
                        #'d': Double (8 bytes)
                        #'h': Short (2 bytes)
                        count = len(datasplice)//4 # Number of bytes to unpack (1 for char)
                        #print(count)
                        unpacked_data = self.unpack_repeated_bytes(datasplice, 'f', count)
                        #print(unpacked_data)
                        
                        x_start = unpacked_data[0]
                        x_end = unpacked_data[2]

                        x_range = np.linspace(x_start, x_end, countDataEntries, True)
                        #print(type(x_range))
                        #print(x_range)
                        #print(len(x_range))
                        
                        self.Deg2Theta = ureg.Quantity(x_range, 'degree') # dataxydfile[:, 0]  # First column
                        
                        ###
                        # Data
                        ###

                        datasplice = contentrawfile[0x40800:0x42BC0]
                        #'i': Integer (4 bytes)
                        #'f': Float (4 bytes)
                        #'d': Double (8 bytes)
                        count = len(datasplice)//4 # Number of bytes to unpack (1 for char)
                        #print(count)
                        unpacked_data = self.unpack_repeated_bytes(datasplice, 'i', count)

                        #print(unpacked_data)
                        #type(unpacked_data)
                        y_data = np.array(unpacked_data, dtype=np.int64)
                        #print(y_data)
                        #print(len(y_data))
                        
                        self.Intensity = ureg.Quantity(y_data, 'dimensionless') #dataxydfile[:, 1]  # Second column
                        
                        # Sanity check
                        if len(x_range) != len(y_data):
                            raise DataFileError(f"The data in file '{self.data_as_dpt_file}' could not parsed. '{countDataEntries}' expected, but {len(y_data)} found!")
                        
                        # Create plot
                        self.figures = self.generate_plots()
                    
        except Exception as e:
            logger.error('Invalid file parsing error.', exc_info=e)
            #logger.error('Invalid file extension for parsing.', exc_info=e)
        # In case something is odd here -> just return
        # if not self.results:
        #    return
        
        

class MeasurementIR(ELNMeasurement, PlotSection, ArchiveSection):
    '''
    Class for handling measurement of IR.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-Measurement-IR',
        a_eln={
            "overview": True,
            "hide": [
                "name",
                "lab_id",
                "method",
                "samples",
                "measurement_identifiers"
            ]
        },
        # a_plotly_graph_object=[
        #     {
        #         "data": [
        #             {
        #                 "x": "#Deg2Theta",
        #                 "y": "#Counts"
        #             }
        #         ],
        #         "layout": {
        #             "title": {
        #                 "text": "Counts over Degree 2Theta"
        #             }
        #         }
        #     }
        # ],
        )
    lab_id = Quantity(
        type=str,
        a_display={
            "visible": False
        },
    )
    data_as_dpt_file = Quantity(
        type=str,
        description="A reference to an uploaded .dpt produced by the IR instrument.",
        a_tabular_parser={
            "parsing_options": {
                "sep": "\\t",
                "comment": "#"
            }
        },
        a_browser={
            "adaptor": "RawFileAdaptor"
        },
        a_eln={
            "component": "FileEditQuantity"
        },
    )
    Wavenumber = Quantity(
        type=np.float64,
        shape=["*"],
        unit='1/cm',
        description='The wavenumber range of the spectrogram',
    )
    Transmittance = Quantity(
        type=np.float64,
        shape=["*"],
        unit='dimensionless',
        description='The transmittance at each wavenumber value, dimensionless',
    )
    
    def generate_plots(self) -> list[PlotlyFigure]:
        """
        Generate the plotly figures for the `MeasurementIR` section.

        Returns:
            list[PlotlyFigure]: The plotly figures.
        """
        figures = []
        #if self.wavelength is None:
        #    return figures

        x_label = 'Wavenumber'
        xaxis_title = f'{x_label} (cm-1)'
        x = self.Wavenumber.to('1/cm').magnitude

        y_label = 'Transmittance'
        yaxis_title = f'{y_label} (a.u.)'
        y = self.Transmittance.to('dimensionless').magnitude

        line_linear = px.line(x=x, y=y)

        line_linear.update_layout(
            title=f'{y_label} over {x_label}',
            xaxis_title=xaxis_title,
            yaxis_title=yaxis_title,
            xaxis=dict(
                fixedrange=False,
            ),
            yaxis=dict(
                fixedrange=False,
            ),
            template='plotly_white',
        )

        figures.append(
            PlotlyFigure(
                label=f'{y_label} linear plot',
                index=0,
                figure=line_linear.to_plotly_json(),
            ),
        )

        return figures
    
    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger'):
        """
        The normalize function of the `MeasurementIR` section.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        
        try:
            # Check if any file is provided
            if self.data_as_dpt_file:
                # Check if the file has the correct extension
                if not self.data_as_dpt_file.endswith('.dpt'):
                    raise DataFileError(f"The file '{self.data_as_dpt_file}' must have a .dpt extension.")
            
                # Otherwise parse the file
                with archive.m_context.raw_file(self.data_as_dpt_file) as xyfile:
                    # Load the data from the file
                    dataxyfile = np.loadtxt(xyfile)
                    
                    # Separate the columns into two variables and copy to 
                    self.Wavenumber = ureg.Quantity(dataxyfile[:, 0], '1/cm') # dataxydfile[:, 0]  # First column
                    self.Transmittance = ureg.Quantity(dataxyfile[:, 1], 'dimensionless') #dataxydfile[:, 1]  # Second column
                    
                    # Otherwise create plot
                    self.figures = self.generate_plots()
        
        except Exception as e:
            logger.error('Invalid file extension for parsing.', exc_info=e)
        # In case something is odd here -> just return
        # if not self.results:
        #    return
        
        


class MeasurementSEM(ELNMeasurement, PlotSection, ArchiveSection):
    '''
    Class for handling measurement of SEM.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-Measurement-SEM',
        a_eln={
            "overview": True,
            "hide": [
                "name",
                "lab_id",
                "method",
                "samples",
                "measurement_identifiers"
            ]
        },
        )
    lab_id = Quantity(
        type=str,
        a_display={
            "visible": False
        },
    )
    data_as_tif_or_tiff_file = Quantity(
        type=str,
        shape=["*"],
        description='''
        A reference to an uploaded .tif produced by the SEM instrument.
        ''',
        a_browser={
            "adaptor": "RawFileAdaptor"
        },
        a_eln={
            "component": "FileEditQuantity"
        },
        repeats=True,
    )
    
    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger'):
        """
        The normalize function of the `MeasurementIR` section.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        
        try:
            
            # Check if any file is provided
            if self.data_as_tif_or_tiff_file:
                self.figures = []
                # Loop over all filenames
                for data_file in self.data_as_tif_or_tiff_file: #.split(" "):
                    # Check if the file has the correct extension
                    if not data_file.endswith('.tif'):
                        if not data_file.endswith('.tiff'):
                            raise DataFileError(f"The file '{data_file}' must have a .tif or .tiff extension.")
                
                    # Otherwise parse the file as binary
                    # with archive.m_context.raw_file(data_file, 'rb') as imagefile:
                    #    archive.m_context.raw_file(data_file) as xyfile:
                    with archive.m_context.raw_file(data_file, 'rb') as imagefile:
                        with Image.open(imagefile) as img:
                            # Get the size of the image
                            img_width, img_height = img.size
                            # print(f"Width: {img_width}, Height: {img_height}")
                            
                             # Convert the image to RGB (necessary for JPEG)
                            img = img.convert('RGB')
                            # Create a BytesIO object to hold the image data
                            buffered = io.BytesIO()
                            # Save the image to the BytesIO object in JPEG format
                            img.save(buffered, format="JPEG")
                            # Get the byte data
                            img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
                            # Create the URI image string
                            uri = f"data:image/jpeg;base64,{img_str}"
                            
                            # see https://plotly.com/python/images/#zoom-on-static-images
                            fig = go.Figure()
                            scale_factor = 0.5
                            fig.add_trace(
                                go.Scatter(
                                    x=[0, img_width * scale_factor],
                                    y=[0, img_height * scale_factor],
                                    mode="markers",
                                    marker_opacity=0
                                )
                            )
                            # Configure axes
                            fig.update_xaxes(
                                visible=False,
                                range=[0, img_width * scale_factor]
                            )

                            fig.update_yaxes(
                                visible=False,
                                range=[0, img_height * scale_factor],
                                # the scaleanchor attribute ensures that the aspect ratio stays constant
                                scaleanchor="x"
                            )
                            
                            # Add image
                            fig.add_layout_image(
                                dict(
                                    x=0,
                                    sizex=img_width * scale_factor,
                                    y=img_height * scale_factor,
                                    sizey=img_height * scale_factor,
                                    xref="x",
                                    yref="y",
                                    opacity=1.0,
                                    layer="below",
                                    sizing="stretch",
                                    source=uri)
                            )
                            # Configure other layout
                            fig.update_layout(
                                width=img_width * scale_factor,
                                height=img_height * scale_factor,
                                margin={"l": 0, "r": 0, "t": 0, "b": 0},
                            )
                            
                            figure_json = fig.to_plotly_json()
                            figure_json['config'] = {'staticPlot': True, 'displayModeBar': False, 'scrollZoom': True, 'responsive': False, 'displaylogo': False, 'dragmode': False}
                            #self.figures.append(PlotlyFigure(label='Measurement SEM', index=0, figure=figure_json))
                            # label=f'{y_label} linear plot',
                            self.figures.append(PlotlyFigure(label=f'Measurement SEM: {data_file}', figure=figure_json))
                            #self.figures = [PlotlyFigure(label=f'Measurement SEM: {data_file}', index=0, figure=figure_json)]
                
        except Exception as e:
            logger.error('Invalid file extension for parsing.', exc_info=e)
        # In case something is odd here -> just return
        # if not self.results:
        #    return
        
        # Otherwise create plot
        #self.figures = self.generate_plots()
        super().normalize(archive, logger)


class MeasurementTEM(ELNMeasurement, PlotSection, ArchiveSection):
    '''
    Class for handling measurement of SEM.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-Measurement-TEM',
        a_eln={
            "overview": True,
            "hide": [
                "name",
                "lab_id",
                "method",
                "samples",
                "measurement_identifiers"
            ]
        },
        )
    lab_id = Quantity(
        type=str,
        a_display={
            "visible": False
        },
    )
    data_as_tif_or_tiff_file = Quantity(
        type=str,
        description='''
        A reference to an uploaded .tif produced by the TEM instrument.
        ''',
        a_tabular_parser={
            "parsing_options": {
                "sep": "\\t",
                "comment": "#"
            }
        },
        a_browser={
            "adaptor": "RawFileAdaptor"
        },
        a_eln={
            "component": "FileEditQuantity"
        },
    )
    
    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger'):
        """
        The normalize function of the `MeasurementIR` section.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        
        try:
            
            # Check if any file is provided
            if self.data_as_tif_or_tiff_file:
                # Check if the file has the correct extension
                if not self.data_as_tif_or_tiff_file.endswith('.tif'):
                    if not self.data_as_tif_or_tiff_file.endswith('.tiff'):
                        raise DataFileError(f"The file '{self.data_as_tif_or_tiff_file}' must have a .tif or .tiff extension.")
            
                # Otherwise parse the file as binary
                # with archive.m_context.raw_file(self.data_as_tif_or_tiff_file, 'rb') as imagefile:
                #    archive.m_context.raw_file(self.data_as_tif_or_tiff_file) as xyfile:
                with archive.m_context.raw_file(self.data_as_tif_or_tiff_file, 'rb') as imagefile:
                    with Image.open(imagefile) as img:
                        # Get the size of the image
                        img_width, img_height = img.size
                        # print(f"Width: {img_width}, Height: {img_height}")
                        
                         # Convert the image to RGB (necessary for JPEG)
                        img = img.convert('RGB')
                        # Create a BytesIO object to hold the image data
                        buffered = io.BytesIO()
                        # Save the image to the BytesIO object in JPEG format
                        img.save(buffered, format="JPEG")
                        # Get the byte data
                        img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
                        # Create the URI image string
                        uri = f"data:image/jpeg;base64,{img_str}"
                        
                        # see https://plotly.com/python/images/#zoom-on-static-images
                        fig = go.Figure()
                        scale_factor = 800.0/img_width # 0.5
                        fig.add_trace(
                            go.Scatter(
                                x=[0, img_width * scale_factor],
                                y=[0, img_height * scale_factor],
                                mode="markers",
                                marker_opacity=0
                            )
                        )
                        # Configure axes
                        fig.update_xaxes(
                            visible=False,
                            range=[0, img_width * scale_factor]
                        )

                        fig.update_yaxes(
                            visible=False,
                            range=[0, img_height * scale_factor],
                            # the scaleanchor attribute ensures that the aspect ratio stays constant
                            scaleanchor="x"
                        )
                        
                        # Add image
                        fig.add_layout_image(
                            dict(
                                x=0,
                                sizex=img_width * scale_factor,
                                y=img_height * scale_factor,
                                sizey=img_height * scale_factor,
                                xref="x",
                                yref="y",
                                opacity=1.0,
                                layer="below",
                                sizing="stretch",
                                source=uri)
                        )
                        # Configure other layout
                        fig.update_layout(
                            width=img_width * scale_factor,
                            height=img_height * scale_factor,
                            margin={"l": 0, "r": 0, "t": 0, "b": 0},
                        )
                        
                        figure_json = fig.to_plotly_json()
                        figure_json['config'] = {'staticPlot': True, 'displayModeBar': False, 'scrollZoom': True, 'responsive': False, 'displaylogo': False, 'dragmode': False}
                        #self.figures.append(PlotlyFigure(label='Measurement SEM', index=0, figure=figure_json))
                        # label=f'{y_label} linear plot',
                        self.figures = [PlotlyFigure(label=f'Measurement TEM: {self.data_as_tif_or_tiff_file}', index=0, figure=figure_json)]
            
        except Exception as e:
            logger.error('Invalid file extension for parsing.', exc_info=e)
        # In case something is odd here -> just return
        # if not self.results:
        #    return
        
        # Otherwise create plot
        #self.figures = self.generate_plots()
        super().normalize(archive, logger)

class RamanData(ArchiveSection):
    """General data section for Raman spectroscopy"""

    m_def = Section(
        label_quantity='name',
    )
    
    name = Quantity(
        type=str,
        default='TestName',
        description='Name of the section or Raman measurement',
        a_eln={'component': 'StringEditQuantity'},
    )
    
    Laser_Excitation_Wavelength = Quantity(
        type=np.float64,
        unit='nanometer',
        description='The wavelength of the laser for Raman spectroscopy.',
    )
    
    data_as_tvf_or_txt_file = Quantity(
        type=str,
        description="A reference to an uploaded TriVista .tvf or .txt file produced by the Raman instrument.",
        a_browser={
            "adaptor": "RawFileAdaptor"
        },
        a_eln={
            "component": "FileEditQuantity"
        },
    )
        
    Raman_shift = Quantity(
        type=np.float64,
        shape=["*"],
        unit='1/centimeter',
        description='The wavenumber range of the spectrogram.',
    )
    Intensity = Quantity(
        type=np.float64,
        shape=["*"],
        unit='dimensionless',
        description='The intensity or counts at each Raman wavenumber value, dimensionless',
    )

class MeasurementRaman(ELNMeasurement, PlotSection, ArchiveSection):
    '''
    Class for handling measurement of Raman spectroscopy.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-Measurement-Raman',
        a_eln={
            "overview": True,
            "hide": [
                "name",
                "lab_id",
                "method",
                "samples",
                "measurement_identifiers"
            ]
        },
        )
            
    lab_id = Quantity(
        type=str,
        a_display={
            "visible": False
        },
    )
    
    data_as_tvb_file = Quantity(
        type=str,
        description="A reference to an uploaded TriVista binary .tvb produced by the Raman instrument.",
        a_browser={
            "adaptor": "RawFileAdaptor"
        },
        a_eln={
            "component": "FileEditQuantity"
        },
    )
    
    Raman_data_entries = SubSection(section_def=RamanData, repeats=True)
    
    
    def generate_plots(self) -> list[PlotlyFigure]:
        """
        Generate the plotly figures for the `MeasurementRaman` section.

        Returns:
            list[PlotlyFigure]: The plotly figures.
        """
        figures = []
        fig = go.Figure()
        
        for r_d_entries in self.Raman_data_entries:
            # Add line plots
            x = r_d_entries.Raman_shift.to('1/centimeter').magnitude
            y = r_d_entries.Intensity.to('dimensionless').magnitude
            fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name=r_d_entries.data_as_tvf_or_txt_file))

        # exemply use the first entry for the units
        x_label = 'Raman shift'
        xaxis_title = f'{x_label} ({self.Raman_data_entries[0].Raman_shift.units:~})'#(1/cm)' the ':~' gives the short form
        
        y_label = 'Intensity'
        yaxis_title = f'{y_label} (a.u.)'
        
        fig.update_layout(
            title=f'{y_label} over {x_label}',
            xaxis_title=xaxis_title,
            yaxis_title=yaxis_title,
            xaxis=dict(
                fixedrange=False,
            ),
            yaxis=dict(
                fixedrange=False,
            ),
            legend=dict(yanchor='top', y=0.99, xanchor='left', x=0.01),
            template='plotly_white',
        )

        figures.append(
            PlotlyFigure(
                label=f'{y_label}-{x_label} linear plot',
                #index=0,
                figure=fig.to_plotly_json(),
            ),
        )

        return figures
    
    def unpack_repeated_bytes(self, byte_data, data_type, count, littleEndianEncoding=True):
        """
        Unpack a series of bytes into a tuple of the same data type.
        'i': Integer (4 bytes)
        'I': Unsigned Int (4 bytes)
        'l': Long (4 bytes)
        'L': Long (8 bytes)
        'f': Float (4 bytes)
        'd': Double (8 bytes)
        'h': Short (2 bytes)
        'b': Signed char (1 byte)
        'B': Unsigned char (1 byte)
        'q': Long long (8 bytes)
        'Q': Unsigned long long (8 bytes)

        :param byte_data: The bytes to unpack.
        :param data_type: The format character for the data type (e.g., 'b' for signed char).
        :param count: The number of items to unpack.
        :param littleEndianEncoding: Flag to determine if the data is in little-endian format.
        :return: A tuple of unpacked values.
        """
        # Determine the endianness based on the flag
        endianness = '<' if littleEndianEncoding else '>'
        
        # Create the format string based on the data type, count, and endianness
        format_string = f'{endianness}{count}{data_type}'
        
        # Unpack the byte data using the constructed format string
        return struct.unpack(format_string, byte_data)
    
    def get_non_empty_chunks_separated_by_null(self, data_slice):
        """
        Get all non-empty chunks of data separated by NULL bytes.

        :param data_slice: The slice of data to split.
        :return: A list of bytes objects, each representing a non-empty chunk of data.
        """
        # Split the data by NULL bytes and filter out empty chunks
        return [chunk for chunk in data_slice.split(b'\x00') if chunk]
    
    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger'):
        """
        The normalize function of the `MeasurementRaman` section.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        # super().normalize(archive, logger)
        try:
            #Check if there's any TriVista binary .tvb file provided in main section
            if self.data_as_tvb_file:
                if not self.data_as_tvb_file.endswith('.tvb'):
                    raise DataFileError(f"The file '{self.data_as_tvb_file}' must have a .tvb extension.")
                
                # Otherwise parse the file
                with archive.m_context.raw_file(self.data_as_tvb_file,'rb') as tvbfile:
                    # Load the data from the file
                    contentTVBfile = tvbfile.read()
                    
                    ###
                    # File Type Version
                    ###
                    datasplice = contentTVBfile[0x0000:0x003] # this should be 'tvb'
                    # 'b': Signed char (1 byte)
                    count = len(datasplice)//1 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'b', count)
                    string_output_file_type = ''.join(chr(b) for b in unpacked_data)
                    #print(string_output_file_type)
                    
                    if string_output_file_type != 'tvb':
                        logger.error(f'This reader may not work for tvb file with header: "{string_output_file_type}"')
                    
                    ###
                    # File Info - Frames and Dataset Length
                    ###
                    datasplice = contentTVBfile[0x0004:0x0016] 
                    # 'h': short (2 byte)
                    count = len(datasplice)//2 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'h', count)
                    #print(unpacked_data)
                    
                    numDatasetLength = int(unpacked_data[1])
                    numFrames = int(unpacked_data[5])
                    #print(numDatasetLength, numFrames)
                    
                    ###
                    # LaserExcitationWavelength
                    ###
                    datasplice = contentTVBfile[0x0025:0x002D]
                    # 'd': double (8 byte)
                    count = len(datasplice)//8 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'd', count)
                    #print(unpacked_data)
                    
                    LaserExcitationWavelength = float(unpacked_data[0])
                    #print(LaserExcitationWavelength)
                    
                    ###
                    # Number of Raman Wavelength entries = NRWE
                    ###
                    datasplice = contentTVBfile[0x002D:0x0031] 
                    # 'I': unsigned integer (4 byte)
                    count = len(datasplice)//4 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'I', count)
                    #print(unpacked_data)
                    
                    NRWE = int(unpacked_data[0])
                    # print(NRWE)
                    
                    ###
                    # List of Raman Wavelength [in nm] convert to Raman Shift = Raman Wavenumber [1/nm]
                    ###
                    datasplice = contentTVBfile[0x0031:0x0031+4*NRWE] 
                    # 'f': float (4 byte)
                    count = len(datasplice)//4 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'f', count)
                    #print(unpacked_data)
                    
                    import numpy as np
                    RamanWavenumber = (1.0/LaserExcitationWavelength-1.0/np.asarray(unpacked_data, dtype=np.float64)) # in 1/nm
                    #print(RamanWavenumber)
                    
                    ###
                    # Character Length of XML section = CLXML
                    ###
                    datasplice = contentTVBfile[0x1534:0x1538] 
                    # 'I': unsigned integer (4 byte)
                    count = len(datasplice)//4 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'I', count)
                    #print(unpacked_data)
                    
                    CLXML = int(unpacked_data[0])
                    #print(CLXML)
                    
                    ###
                    # XML part
                    ###
                    datasplice = contentTVBfile[0x1538:0x1538+1*CLXML]
                    # 'b': Signed char (1 byte)
                    count = len(datasplice)//1 # Number of bytes to unpack (1 for char)
                    #print(count)
                    unpacked_data = self.unpack_repeated_bytes(datasplice, 'b', count)
                    string_output_xml = ''.join(chr(b) for b in unpacked_data)
                    #print(string_output_xml)
                    
                    ###
                    # List of Intensity counts for every frame in file
                    ###
                    offsetHeader = 0x1538+1*CLXML + 3*4 + 8 + 101
                    
                    # Create subsection if not existing
                    if not self.Raman_data_entries:
                        self.Raman_data_entries = []
                        # Ensure the list is long enough
                        while len(self.Raman_data_entries) < numFrames:
                            self.Raman_data_entries.append(RamanData())  # Append a placeholder value
                    
                    # Create new if not sufficient long enough - overwrites the default
                    if len(self.Raman_data_entries) < numFrames:
                        self.Raman_data_entries = []
                        while len(self.Raman_data_entries) < numFrames:
                            self.Raman_data_entries.append(RamanData())  # Append a placeholder value
                    
                    #print(len(self.Raman_data_entries))
                    
                    # Do this for every frame in file
                    for frame in range(0,numFrames,1):
                        #print(frame)
                        datasplice = contentTVBfile[offsetHeader:offsetHeader+4*NRWE] 
                        # 'f': float (4 byte)
                        count = len(datasplice)//4 # Number of bytes to unpack (1 for char)
                        #print(count)
                        unpacked_data = self.unpack_repeated_bytes(datasplice, 'f', count)
                        #print(unpacked_data)
                        
                        import numpy as np
                        IntensityCount = np.asarray(unpacked_data, dtype=np.float64)
                        #print(IntensityCount)
                        
                        # Separate the columns into two variables and copy to 
                        self.Raman_data_entries[frame].Raman_shift = ureg.Quantity(RamanWavenumber, '1/nanometer')
                        self.Raman_data_entries[frame].Intensity = ureg.Quantity(IntensityCount, 'dimensionless')
                        self.Raman_data_entries[frame].Laser_Excitation_Wavelength = ureg.Quantity(LaserExcitationWavelength, 'nanometer')
                        
                        offsetHeader += 4*NRWE + 3*4 + 8 + 101 # specific after every frame 
                    
                    
            #Check if any file is provided in any subsection for .tvb or .txt files
            for r_d_entries in self.Raman_data_entries:
                if r_d_entries.data_as_tvf_or_txt_file:
                    # Check if the file has the correct extension: TriVista tvf or plain 2-column txt
                    if not r_d_entries.data_as_tvf_or_txt_file.endswith('.tvf') and not r_d_entries.data_as_tvf_or_txt_file.endswith('.txt'):
                        #print("Expect Data File Error")
                        raise DataFileError(f"The file '{r_d_entries.data_as_tvf_or_txt_file}' must have a .tvf or .txt extension.")
                    
                    # Otherwise parse the file with *.txt
                    if r_d_entries.data_as_tvf_or_txt_file.endswith('.txt'):
                        with archive.m_context.raw_file(r_d_entries.data_as_tvf_or_txt_file) as xyfile:
                            # Load the data from the file
                            import numpy as np
                            dataxyfile = np.loadtxt(xyfile)
                            
                            # Separate the columns into two variables and copy to 
                            r_d_entries.Raman_shift = ureg.Quantity(dataxyfile[:, 0], '1/centimeter') # dataxydfile[:, 0]  # First column
                            r_d_entries.Intensity = ureg.Quantity(dataxyfile[:, 1], 'dimensionless') #dataxydfile[:, 1]  # Second column
                    
                    # Otherwise parse the file with *.tvf
                    if r_d_entries.data_as_tvf_or_txt_file.endswith('.tvf'):
                        with archive.m_context.raw_file(r_d_entries.data_as_tvf_or_txt_file) as xyfile:
                            #Load the data from the file
                            contentxyfile = xyfile.read()
                            
                            #use additional packages
                            import xmltodict, json
                            dataxyfile = xmltodict.parse(contentxyfile)
                            
                            unitWave = dataxyfile['XmlMain']['Documents']['Document']['xDim']['Calibration']['@Unit'].lower()
                            calibrationLaserWave = float(dataxyfile['XmlMain']['Documents']['Document']['xDim']['Calibration']['@LaserWave'])
                            r_d_entries.Laser_Excitation_Wavelength = ureg.Quantity(calibrationLaserWave, unitWave)
                            
                            #Read the actual Raman wavelength data
                            RamanWavelength=dataxyfile['XmlMain']['Documents']['Document']['xDim']['Calibration']['@ValueArray']
                            # first number (=int) gives the number of data entries
                            RamanWavelengthData = [int(x) if x.isdigit() else float(x) for x in RamanWavelength.split('|')]
                            
                            ### Conversion from Wavelength[nm] to Wavenumber[1/cm]
                            # $\Delta \omega [cm^{-1}] = ( \frac{1}{\lambda_{laser}} - \frac{1}{\lambda_{}}) \cdot 10â·$
                            
                            import numpy as np
                            RamanWavenumber = (1.0/calibrationLaserWave-1.0/np.asarray(RamanWavelengthData[1:], dtype=np.float64)) # in 1/nm
                            
                            # Read-in of Intensity Counts
                            IntensityString = dataxyfile['XmlMain']['Documents']['Document']['Data']['Frame']['#text']
                            Intensity = np.asarray([float(x) for x in IntensityString.split(';')], dtype=np.float64)
                            
                            # Archive the data
                            r_d_entries.Raman_shift = ureg.Quantity(RamanWavenumber, f'1/{unitWave}') # dataxydfile[:, 0]  # First column
                            r_d_entries.Intensity = ureg.Quantity(Intensity, 'dimensionless') #dataxydfile[:, 1]  # Second column
                            
            
        except Exception as e:
            logger.error('Invalid file extension for parsing.', exc_info=e)
        
        if self.Raman_data_entries:
            #Otherwise create plot
            self.figures = self.generate_plots()
        
        super().normalize(archive, logger)




class CRC1415SampleOverview(ELNSubstance, ReadableIdentifiers, EntryData, ArchiveSection):
    '''
    Class autogenerated from yaml schema for ELNSubstance.
    '''
    m_def = Section(
        categories=[CRC1415Category],
        label='CRC1415-SampleOverview',
        a_eln={
            "lane_width": '600px',
            "properties": {
                "order": [
                    "tags",
                    "name",
                    "short_name",
                    "institute",
                    "owner",
                    "datetime",
                    "lab_id",
                    "molecular_formula",
                    "substance_type",
                    "sample_is_from_collaboration",
                    "Sample_reference_from_collaboration",
                    "description",
                    "chemicals"
                ]
            }
        },
    )
    name = Quantity(
        type=str,
        a_eln={
            "component": "StringEditQuantity"
        },
        default="Default Sample Name",
    )
    tags = Quantity(
        type=MEnum(['internal', 'collaboration', 'project', 'other']),
        a_eln={
            "component": "AutocompleteEditQuantity"
        },
        shape=["*"],
    )
    chemicals = Quantity(
        type=CRC1415Chemical,
        a_eln={
            "component": "ReferenceEditQuantity"
        },
        shape=["*"],
    )
    substance_type = Quantity(
        type=MEnum(['crystalline solid', 'powder', 'solution', 'other']),
        a_eln={
            "component": "RadioEnumEditQuantity"
        },
    )
    sample_is_from_collaboration = Quantity(
        type=bool,
        a_eln={
            "component": "BoolEditQuantity"
        },
        default=False,
    )
    Sample_reference_from_collaboration = Quantity(
        type='CRC1415SampleOverview',
        description='If sample is received by collaboration, then reference it here.',
        a_eln={
            "component": "ReferenceEditQuantity"
        },
        shape=["*"],
    )
    
    molecular_formula = Quantity(
        type=str,
        a_eln={
            "component": "StringEditQuantity"
        },
        )
    
    Other_reference_to_measurement = Quantity(
        type=ELNMeasurement,
        description='If sample is measure otherwise, then reference it here.',
        a_eln={
            "component": "ReferenceEditQuantity"
        },
        shape=["*"],
    )
    
    IR_Instrument = SubSection(
        section_def=IRInstrument,
        repeats=True,
    )
    Contributors = SubSection(
        section_def=Contributors,
        repeats=True,
    )
    
    Measurement_XRD = SubSection(
        section_def=MeasurementXRD,
        repeats=True,
    )
    
    Measurement_IR = SubSection(
        section_def=MeasurementIR,
        repeats=True,
    )
    
    Measurement_SEM = SubSection(
        section_def=MeasurementSEM,
        repeats=True,
    )
    
    Measurement_TEM =SubSection(
       section_def=MeasurementTEM,
       repeats=True,
    )
    
    Measurement_Raman =SubSection(
       section_def=MeasurementRaman,
       repeats=True,
    )
    

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        '''
        The normalizer for the `CRC1415 Sample` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        '''
        # in case only molecular_formula is provided
        if self.molecular_formula and self.pure_substance is None:
            #if self.substance_name and self.pure_substance is None:
            self.pure_substance = PureSubstanceSection(name=self.molecular_formula, molecular_formula=self.molecular_formula)
            #self.pure_substance = PubChemPureSubstanceSection(name=self.molecular_formula)
            self.pure_substance.normalize(archive, logger)
        elif self.molecular_formula and self.pure_substance is not None:
            # PureSubstanceSection already exists and we need to update
            self.pure_substance = None
            self.pure_substance = PureSubstanceSection(name=self.molecular_formula, molecular_formula=self.molecular_formula)
            self.pure_substance.molecular_formula = self.molecular_formula
            # we need to delete manually the results section as
            # elements will by populate by System.normalize fct
            self.elemental_composition = None
            archive.results.material.elements = []
            archive.results.material.elemental_composition = []
            self.pure_substance.normalize(archive, logger)
            
        super().normalize(archive, logger)


class MeasurementExample(ELNMeasurement, PlotSection, ArchiveSection):
    '''
    Class with PlotSection also shown in OverviewClass.
    '''
    m_def = Section(
        a_eln={
            "overview": True,
        },
        )
        
    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger'):
        # super().normalize(archive, logger)
        # Otherwise create plot
        fig = px.scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16])
        
        self.figures = []
        self.figures.append(PlotlyFigure(label='Measurement Example:', figure=fig.to_plotly_json()))
        


class OverviewClass(EntryData, ArchiveSection):
    '''
    Class autogenerated from yaml schema for ELNSubstance.
    '''
    m_def = Section()
    
    Measurement_Example =SubSection(
       section_def=MeasurementExample,
       repeats=True,
    )

m_package.__init_metainfo__()
